# 패키지 임포트
# os 패키지 임포트
# 파이토치 패키지 임포트
# nn 패키지 임포트
# MNIST 데이터셋 불러오기
# ToTensor 클래스 임포트
# DataLoader 클래스 임포트
# Adam 클래스 임포트

# hyperparameter 선언(학습률, 이미지 사이즈, 클래스 개수, 배치 사이즈, 은닉층 사이즈, 에포크 수, 결과 저장 폴더)

# 디바이스 설정

# 상위 저장 폴더가 없으면 상위 저장 폴더 생성
# 결과 저장할 하위 타깃 폴더 생성
# 하위 타깃 폴더 이름
# 하위 타깃 폴더 경로
# 하위 타깃 폴더 생성
# 타깃 폴더에 하이퍼파라미터 저장
# 타깃 폴더에 hparam.txt 파일 생성


# 모델 설계도 그리기
# nn.Module을 상속받는 MLP 클래스 선언
# 클래스 초기화: MLP 레이어 정의
# 상속받은 상위 클래스의 초기화 메서드 호출
# 이미지 사이즈 저장
# 첫 번째 MLP 레이어 선언(입력층 -> 은닉층1)
# 두 번째 MLP 레이어 선언(은닉층1 -> 은닉층2)
# 세 번째 MLP 레이어 선언(은닉층2 -> 은닉층3)
# 네 번째 MLP 레이어 선언(은닉층3 -> 출력층)
# 순전파: 데이터가 레이어 통과하는 방식 지정
# 입력 텐서의 배치 크기 저장(x: [batch_size, 28, 28, 1])
# 28*28 픽셀 이미지를 1차원 벡터로 변환(펼치기)
# 순전파 수행: 입력 이미지를 순차적으로 MLP 레이어에 통과시킴
# [batch_size, 500]
# [batch_size, 500]
# [batch_size, 500]
# [batch_size, 10]
# 최종 출력 반환

 
# 설계도를 바탕으로 모델 만들기 <- hyperparmeter 사용 

# 데이터 불러오기 
# dataset 설정(학습, 테스트 데이터)
# dataloader 설정(학습, 테스트 데이터)

# Loss 선언 
# Optimizer 선언

# 학습을 위한 반복 (Loop) for / while
# 입력할 데이터를 위해 데이터 준비 (dataloader)
        # 데이터와 타깃을 디바이스에 올리기
        # 모델에 데이터를 넣기 
        # 모델의 출력과 정답을 비교하기 (Loss 사용)
        # 역전파 수행
        # 가중치 업데이트
        # 그래디언트 초기화
        
        # 100번 반복마다 loss 출력